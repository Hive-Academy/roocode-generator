## Implementation Plan: Refine AI Magic Generator Rules Output (TSK-021)

### Overview

This plan outlines the technical steps to refine the output of the AI Magic Generator when generating rules. The primary goal is to eliminate conversational filler from the LLM response and ensure the output contains only the list of rules in a consistent, parseable format. This will involve modifying the prompt template used for rules generation and potentially adjusting the response processing logic. The changes will be carefully implemented and tested to avoid negative impacts on other generator outputs.

Key implementation decisions will revolve around the specific instructions added to the prompt to enforce the desired output format and the method for parsing the LLM's response.

Files likely to be modified:

- `src/generators/ai-magic-generator.ts` (or related prompt building/processing files)
- `src/core/templating/rules-prompt-builder.ts` (or similar prompt building logic)
- Test files related to `ai-magic-generator` and `rules-prompt-builder`.

### Implementation Strategy

The high-level approach is to modify the prompt template used by the `AiMagicGenerator` specifically for rules generation. We will add explicit instructions to the LLM to output _only_ the list of rules in a predefined, structured format (e.g., a Markdown list or JSON array). The response processing logic will be reviewed to ensure it correctly handles this new format and can robustly extract the rules, ignoring any potential residual filler. We will rely on existing prompt building and template management services (`RulesPromptBuilder`, `TemplateManager`).

Technical challenges include ensuring the LLM consistently adheres to the strict output format instructions and handling potential variations in the response despite the instructions.

### Acceptance Criteria Mapping

- **The output generated by the AI Magic Generator for rules contains _only_ the list of rules.**
  - Satisfied by: Modifying the prompt to request only rules and adjusting response parsing to extract only the rule list.
  - Verified through: Unit tests for response parsing and integration tests for the generator output.
- **The generated rule list is in a consistent and expected format (e.g., markdown list, JSON array).**
  - Satisfied by: Specifying the exact required format in the prompt instructions and validating the parsed output format.
  - Verified through: Unit tests validating the structure of the parsed rules.
- **There are no introductory or concluding conversational phrases from the LLM in the generated rule file.**
  - Satisfied by: Explicitly instructing the LLM in the prompt to avoid conversational text and implementing robust parsing that discards such text.
  - Verified through: Manual inspection of generated output and potentially pattern matching in tests.
- **The change does not negatively impact the generation of other content types by the AI Magic Generator or other generators.**
  - Satisfied by: Ensuring changes are scoped specifically to rules generation prompts/processing and running existing integration tests for other generator types.
  - Verified through: Running existing test suites and potentially adding specific integration tests if needed.

### Implementation Subtasks

#### 1. Analyze and Modify Rules Prompt Template

**Status**: Completed

**Description**: Examine the current prompt template or logic used by `AiMagicGenerator` for generating rules. Identify where instructions for the LLM are constructed. Modify the prompt to include clear, unambiguous instructions for the LLM to output _only_ the list of rules in a specific, parseable format (e.g., a Markdown unordered list). Explicitly instruct the LLM to avoid any introductory or concluding remarks.

**Files to Modify**:

- [`src/generators/ai-magic-generator.ts`](src/generators/ai-magic-generator.ts) - Identify prompt construction logic.
- [`src/core/templating/rules-prompt-builder.ts`](src/core/templating/rules-prompt-builder.ts) - Modify prompt building logic/template.

**Implementation Details**:

```typescript
// Example: Modify prompt template string or builder logic
const rulesPrompt = `
... existing prompt content ...

Please provide ONLY the list of rules as a Markdown unordered list. Do not include any introductory or concluding sentences.

- Rule 1: Description
- Rule 2: Description
...
`;
```

**Testing Requirements**:

- Unit tests for `RulesPromptBuilder` (or equivalent) to verify the modified prompt structure includes the new instructions.
- Test cases: Verify prompt includes specific phrases like "ONLY the list of rules", "Markdown unordered list", "Do not include any introductory or concluding sentences".

**Related Acceptance Criteria**:

- The output generated by the AI Magic Generator for rules contains _only_ the list of rules.
- The generated rule list is in a consistent and expected format (e.g., markdown list, JSON array).
- There are no introductory or concluding conversational phrases from the LLM in the generated rule file.

**Estimated effort**: 30-45 minutes

**Required Delegation Components**:

- Implementation components for Junior Coder:
  - None directly suitable for isolated delegation due to tight coupling with prompt building logic.
- Testing components for Junior Tester:
  - **Prompt Structure Tests**: Write unit tests for the prompt building logic to assert the presence of the new instructions and the expected format request in the generated prompt string.
  - Note: Testing was deferred based on user preference.

**Delegation Success Criteria**:

- Junior Tester components must: Accurately verify the structure and content of the generated prompt string based on the modified logic.
- Integration requirements: The tests should integrate with the existing test suite for the prompt building service.

**Delegation Decisions**:

- No components were delegated for this subtask due to the tight coupling of the prompt building logic and the small scope of changes required.
- Testing was deferred based on user preference.

**Redelegation History**: None

#### 2. Update Rules Response Processing

**Status**: Not Started

**Description**: Examine the code in `AiMagicGenerator` (or related services) that processes the LLM's response for rules generation. Update this logic to robustly extract the rule list based on the specified format (e.g., parsing a Markdown list). Implement logic to discard any text before or after the expected list format. Add validation to ensure the extracted content matches the expected structure of a rule list.

**Files to Modify**:

- [`src/generators/ai-magic-generator.ts`](src/generators/ai-magic-generator.ts) - Modify response processing logic.
- [`src/core/llm/response-parser.ts`](src/core/llm/response-parser.ts) (or similar) - Potentially add/modify parsing logic.

**Implementation Details**:

```typescript
// Example: Parsing logic
function extractRulesFromResponse(response: string): string[] {
  // Implement parsing based on expected format (e.g., regex for markdown list items)
  const ruleMatches = response.match(/^- .+/gm);
  if (!ruleMatches) {
    // Handle cases where format is not matched, potentially log warning or throw error
    return [];
  }
  return ruleMatches.map((match) => match.substring(2).trim()); // Extract rule text
}
```

**Testing Requirements**:

- Unit tests for the response processing logic.
- Test cases:
  - Response contains only the expected Markdown list.
  - Response contains the list with leading/trailing conversational text.
  - Response contains unexpected format.
  - Response is empty or null.

**Related Acceptance Criteria**:

- The output generated by the AI Magic Generator for rules contains _only_ the list of rules.
- The generated rule list is in a consistent and expected format (e.g., markdown list, JSON array).
- There are no introductory or concluding conversational phrases from the LLM in the generated rule file.

**Estimated effort**: 45-60 minutes

**Required Delegation Components**:

- Implementation components for Junior Coder:
  - **Markdown List Parser**: Implement a utility function or class method specifically for parsing a Markdown unordered list from a string, returning an array of list item strings. This component should be pure and testable in isolation.
- Testing components for Junior Tester:
  - **Response Parsing Tests**: Write unit tests for the response processing logic, including tests for the delegated Markdown list parser component, covering various input scenarios (valid format, format with filler, incorrect format, empty).

**Delegation Success Criteria**:

- Junior Coder components must: Correctly parse Markdown unordered lists and return an array of strings, handling edge cases like empty input or no list items.
- Junior Tester components must: Ensure the response processing logic correctly uses the parser and handles different LLM response variations robustly, verifying that only the rule list is extracted.
- Integration requirements: The delegated parser component must be correctly integrated into the `AiMagicGenerator`'s response processing flow.

**Redelegation History**: None

#### 3. Integration and Verification

**Status**: Not Started

**Description**: Integrate the modified prompt building and response processing logic within the `AiMagicGenerator`. Run existing unit and integration tests for `AiMagicGenerator` and other generators to ensure no negative impacts. Manually verify the output of the rules generator to confirm the absence of conversational filler and the correct format.

**Files to Modify**:

- [`src/generators/ai-magic-generator.ts`](src/generators/ai-magic-generator.ts) - Integrate modified components.

**Implementation Details**:

```typescript
// Example: Integration points
async generateRules(...) {
  const prompt = this.rulesPromptBuilder.buildPrompt(...); // Use modified builder
  const llmResponse = await this.llmAgent.getCompletion(prompt, ...);
  const rules = this.responseProcessor.extractRulesFromResponse(llmResponse.text); // Use updated processor
  // ... rest of generation logic
}
```

**Testing Requirements**:

- Run all existing unit tests for `AiMagicGenerator`, `RulesPromptBuilder`, and response processing.
- Run existing integration tests for `AiMagicGenerator`.
- Run existing integration tests for _other_ generators to confirm no regressions.
- Manual verification of generated rules file content.

**Related Acceptance Criteria**:

- The output generated by the AI Magic Generator for rules contains _only_ the list of rules.
- The generated rule list is in a consistent and expected format (e.g., markdown list, JSON array).
- There are no introductory or concluding conversational phrases from the LLM in the generated rule file.
- The change does not negatively impact the generation of other content types by the AI Magic Generator or other generators.

**Estimated effort**: 30-45 minutes

**Required Delegation Components**:

- Implementation components for Junior Coder: None.
- Testing components for Junior Tester:
  - **Regression Test Suite Execution**: Execute the full test suite (`npm test`) and report results.
  - **Manual Output Verification**: Perform manual checks on generated rule files for conversational filler and format consistency.

**Delegation Success Criteria**:

- Junior Tester components must: Accurately report test results and provide clear feedback from manual verification, confirming all acceptance criteria related to output format and filler are met and no regressions occurred.
- Integration requirements: The manual verification process should be clearly documented.

**Redelegation History**: None

### Implementation Sequence

1. Analyze and Modify Rules Prompt Template - Focus on instructing the LLM clearly.
2. Update Rules Response Processing - Build robust parsing logic based on the expected format.
3. Integration and Verification - Combine the changes and ensure everything works as expected without regressions.

### Testing Strategy

The testing strategy will combine unit tests for the modified components (prompt building, response parsing) with existing integration tests for the `AiMagicGenerator` and other generators. Manual verification of the generated output will also be crucial to confirm the absence of conversational filler, which can be difficult to fully automate.

Required tests:

- Unit tests for `RulesPromptBuilder` (or equivalent) to verify prompt content.
- Unit tests for the response parsing logic, including the delegated Markdown list parser, covering various LLM response formats.
- Existing integration tests for `AiMagicGenerator` to ensure it still generates rules correctly with the new logic.
- Existing integration tests for other generators to confirm no regressions.

Critical test cases:

- LLM response contains only the expected Markdown list of rules.
- LLM response contains the Markdown list with leading/trailing conversational text.
- LLM response uses a slightly different but still parseable format.
- LLM response is completely off-format or empty.
- Running other generator types (e.g., documentation, code snippets) to ensure their output is unchanged.
